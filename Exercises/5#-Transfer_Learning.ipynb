{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05c8f32c",
   "metadata": {},
   "source": [
    "# Transfer Learning with Tensorflow Part 1: Feature Extraction\n",
    "\n",
    "Transfer learning is leveraging a working model's existing architecture and learned patterns for our own problems.\n",
    "There are two main benefits:\n",
    "1. Can leverage an existing neural network architecture proven to work on problems similat to our own.\n",
    "2. Can leverage a working neural network achitecture which has already learned patterns to similar data to our own, then we can adapt those patterns to our own data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf950ac",
   "metadata": {},
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fb39cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 directories and 0 images in : ../data/10_food_classes_10_percent\n",
      "There are 10 directories and 0 images in : ../data/10_food_classes_10_percent\\test\n",
      "There are 0 directories and 250 images in : ../data/10_food_classes_10_percent\\test\\chicken_curry\n",
      "There are 0 directories and 250 images in : ../data/10_food_classes_10_percent\\test\\chicken_wings\n",
      "There are 0 directories and 250 images in : ../data/10_food_classes_10_percent\\test\\fried_rice\n",
      "There are 0 directories and 250 images in : ../data/10_food_classes_10_percent\\test\\grilled_salmon\n",
      "There are 0 directories and 250 images in : ../data/10_food_classes_10_percent\\test\\hamburger\n",
      "There are 0 directories and 250 images in : ../data/10_food_classes_10_percent\\test\\ice_cream\n",
      "There are 0 directories and 250 images in : ../data/10_food_classes_10_percent\\test\\pizza\n",
      "There are 0 directories and 250 images in : ../data/10_food_classes_10_percent\\test\\ramen\n",
      "There are 0 directories and 250 images in : ../data/10_food_classes_10_percent\\test\\steak\n",
      "There are 0 directories and 250 images in : ../data/10_food_classes_10_percent\\test\\sushi\n",
      "There are 10 directories and 0 images in : ../data/10_food_classes_10_percent\\train\n",
      "There are 0 directories and 75 images in : ../data/10_food_classes_10_percent\\train\\chicken_curry\n",
      "There are 0 directories and 75 images in : ../data/10_food_classes_10_percent\\train\\chicken_wings\n",
      "There are 0 directories and 75 images in : ../data/10_food_classes_10_percent\\train\\fried_rice\n",
      "There are 0 directories and 75 images in : ../data/10_food_classes_10_percent\\train\\grilled_salmon\n",
      "There are 0 directories and 75 images in : ../data/10_food_classes_10_percent\\train\\hamburger\n",
      "There are 0 directories and 75 images in : ../data/10_food_classes_10_percent\\train\\ice_cream\n",
      "There are 0 directories and 75 images in : ../data/10_food_classes_10_percent\\train\\pizza\n",
      "There are 0 directories and 75 images in : ../data/10_food_classes_10_percent\\train\\ramen\n",
      "There are 0 directories and 75 images in : ../data/10_food_classes_10_percent\\train\\steak\n",
      "There are 0 directories and 75 images in : ../data/10_food_classes_10_percent\\train\\sushi\n"
     ]
    }
   ],
   "source": [
    "# How many images in each folder?\n",
    "import os\n",
    "\n",
    "# Walk through 10 percent data directory and list number of files\n",
    "for dirpath, dirnames, filenames in os.walk(\"../data/10_food_classes_10_percent\"):\n",
    "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in : {dirpath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a67dee8",
   "metadata": {},
   "source": [
    "### Creating the data loaders (preparing the data)\n",
    "We'll use the ImageDataGenerator class to load in our images in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75ac5b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Images:\n",
      "Found 750 images belonging to 10 classes.\n",
      "Testing images:\n",
      "Found 2500 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Setup data inputs\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dir = \"../data/10_food_classes_10_percent/train/\"\n",
    "test_dir = \"../data/10_food_classes_10_percent/test/\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "print(\"Training Images:\")\n",
    "train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n",
    "                                                          target_size=IMAGE_SHAPE,\n",
    "                                                          batch_size=BATCH_SIZE,\n",
    "                                                          class_mode=\"categorical\")\n",
    "print(\"Testing images:\")\n",
    "test_data_10_percent = test_datagen.flow_from_directory(test_dir,\n",
    "                                                          target_size=IMAGE_SHAPE,\n",
    "                                                          batch_size=BATCH_SIZE,\n",
    "                                                          class_mode=\"categorical\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc21279",
   "metadata": {},
   "source": [
    "### Setting up callbacks (things to run whilst our model trains)\n",
    "\n",
    "Callbacks are extra functionality we can add to our models to be performed during or after training.\n",
    "Some of the most popular callbacks are:\n",
    "* Tracking experiments with the TensorBoard callback.\n",
    "* Model checkpoint with the modelCheckpoint callback.\n",
    "* Stopping a model from training (before it trains too long and overfits) with the Early Stopping callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "173f03d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorBoard callback (functionized because we need to create  a new one for each model)\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "def create_tensorboard_callback(dir_name, experiment_name):\n",
    "    log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "    print(f\"Saving Tensorboard log files to: {log_dir}\")\n",
    "    return tensorboard_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1386251",
   "metadata": {},
   "source": [
    "### Creating models using TensorFlow Hub\n",
    "\n",
    "In the pas we've used TensorFlow to create our own models layers by layer from scratch.\n",
    "\n",
    "Now we're going to do a similar process, except majority of our model's layers are going to come from Tensorflow hub.\n",
    "\n",
    "we can access pretrained models on tfhub.dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a9fd548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare the following two models:\n",
    "resnet_url = \"https://www.kaggle.com/models/google/resnet-v2/TensorFlow2/101-feature-vector/2\"\n",
    "\n",
    "efficientnet_url = \"https://www.kaggle.com/models/tensorflow/efficientnet/TensorFlow2/b0-feature-vector/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d354cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b668545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a create_model() function to create a model from a URL\n",
    "def create_model(model_url, num_classes=10):\n",
    "    \"\"\"\n",
    "    Takes a TensorFlow Hub URL and creates a Keras Sequential model with it.\n",
    "\n",
    "    Args:\n",
    "        model_url (str): A Tensorflow hub/Kaggle feature extraction URL\n",
    "        num_classes (int): Number of output neurons in the output layer. Default 10.\n",
    "\n",
    "    Returns:\n",
    "        An uncompiled Keras Sequential model with model_url as a feature extractor layer and\n",
    "        Dense output layer with num_classes output neurons\n",
    "    \"\"\"\n",
    "\n",
    "    # Download the pretrained model and save it as a Keras layer\n",
    "    feature_extractor_layer = hub.KerasLayer(model_url, trainable=False, name=\"Feature_Extraction_Layer\",\n",
    "                                             input_shape=IMAGE_SHAPE+(3,)) # freeze the already learned patterns with trainable false\n",
    "\n",
    "    # Create the model.\n",
    "    model = tf.keras.Sequential([\n",
    "        feature_extractor_layer,\n",
    "        layers.Dense(num_classes, activation=\"softmax\", name=\"Output_Layer\")\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f926a0",
   "metadata": {},
   "source": [
    "### Creating ResNet TensorFlow hub feature extraction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "673d971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ResNet Model\n",
    "resnet_model = create_model(resnet_url, num_classes=train_data_10_percent.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b393a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "resnet_model.compile(loss=\"categorical_crossentropy\",\n",
    "                     optimizer=tf.keras.optimizers.Adam(),\n",
    "                     metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55736c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Tensorboard log files to: ../tensorflow_hub/resnetv2/20251225-151741\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 70s 3s/step - loss: 0.2594 - accuracy: 0.9547 - val_loss: 0.6096 - val_accuracy: 0.7996\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 69s 3s/step - loss: 0.2124 - accuracy: 0.9680 - val_loss: 0.6049 - val_accuracy: 0.8004\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 98s 4s/step - loss: 0.1768 - accuracy: 0.9800 - val_loss: 0.5889 - val_accuracy: 0.8012\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 73s 3s/step - loss: 0.1492 - accuracy: 0.9880 - val_loss: 0.5843 - val_accuracy: 0.8064\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 72s 3s/step - loss: 0.1269 - accuracy: 0.9920 - val_loss: 0.5824 - val_accuracy: 0.8056\n"
     ]
    }
   ],
   "source": [
    "# Let's fit our resnet model to the data.\n",
    "resnet_history = resnet_model.fit(train_data_10_percent,\n",
    "                                  epochs=5,\n",
    "                                  steps_per_epoch=len(train_data_10_percent),\n",
    "                                  validation_data=test_data_10_percent,\n",
    "                                  validation_steps=len(test_data_10_percent),\n",
    "                                  callbacks=[create_tensorboard_callback(dir_name=\"../tensorflow_hub\",\n",
    "                                                                         experiment_name=\"resnetv2\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c8368b",
   "metadata": {},
   "source": [
    "### Creating and Testing EfficientNetB0 TensorFlow Hub Feature  Extraction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "972eaa1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Tensorboard log files to: ../tensorflow_hub/efficientnetb0/20251225-153358\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 21s 731ms/step - loss: 1.8393 - accuracy: 0.4093 - val_loss: 1.2859 - val_accuracy: 0.7256\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 16s 699ms/step - loss: 1.0622 - accuracy: 0.7547 - val_loss: 0.8594 - val_accuracy: 0.8144\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 16s 699ms/step - loss: 0.7606 - accuracy: 0.8227 - val_loss: 0.6909 - val_accuracy: 0.8440\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 17s 711ms/step - loss: 0.6133 - accuracy: 0.8587 - val_loss: 0.6061 - val_accuracy: 0.8540\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 16s 698ms/step - loss: 0.5153 - accuracy: 0.8827 - val_loss: 0.5516 - val_accuracy: 0.8640\n"
     ]
    }
   ],
   "source": [
    "# Create EfficientNetB0 feature extractor model\n",
    "efficientnet_model = create_model(model_url=efficientnet_url,\n",
    "                                  num_classes=train_data_10_percent.num_classes)\n",
    "\n",
    "# Compile the model\n",
    "efficientnet_model.compile(loss=\"categorical_crossentropy\",\n",
    "                           optimizer=tf.keras.optimizers.Adam(),\n",
    "                           metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model to our 10% of training data.\n",
    "efficientnet_history = efficientnet_model.fit(train_data_10_percent,\n",
    "                                              epochs=5,\n",
    "                                              steps_per_epoch=len(train_data_10_percent),\n",
    "                                              validation_data=test_data_10_percent,\n",
    "                                              validation_steps=len(test_data_10_percent),\n",
    "                                              callbacks=[create_tensorboard_callback(dir_name=\"../tensorflow_hub\",\n",
    "                                                                         experiment_name=\"efficientnetb0\")])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
