{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce4a3209",
   "metadata": {},
   "source": [
    "# Natural Language Processing with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33f5e5a",
   "metadata": {},
   "source": [
    "### Lets import our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a85b7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"../data/nlp_getting_started/train.csv\")\n",
    "test_df = pd.read_csv(\"../data/nlp_getting_started/test.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e5db6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffling the data frame:\n",
    "train_df_shuffled = train_df.sample(frac=1, random_state=42)   # shuffle with random_state=42 for reproducibility\n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80ab728a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "560b52b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    4342\n",
       "1    3271\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many examples of each class?\n",
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01fe8e5",
   "metadata": {},
   "source": [
    "\n",
    "Since we have two target values, we're dealing with a binary classification problem.\n",
    "\n",
    "It's fairly balanced too, about 60% negative class (target = 0) and 40% positive class (target = 1).\n",
    "\n",
    "Where,\n",
    "\n",
    "1 = a real disaster Tweet\n",
    "0 = not a real disaster Tweet\n",
    "And what about the total number of samples we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "204b201a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 7613\n",
      "Total test samples: 3263\n",
      "Total samples: 10876\n"
     ]
    }
   ],
   "source": [
    "# How many samples total?\n",
    "print(f\"Total training samples: {len(train_df)}\")\n",
    "print(f\"Total test samples: {len(test_df)}\")\n",
    "print(f\"Total samples: {len(train_df) + len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c902d9",
   "metadata": {},
   "source": [
    "### Split data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3c92db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # type: ignore\n",
    "\n",
    "# Use train_test_split to split training data into training and validation sets\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
    "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
    "                                                                            test_size=0.1, # dedicate 10% of samples to validation set\n",
    "                                                                            random_state=42) # random state for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb916092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 6851, 762, 762)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the lengths\n",
    "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b11d92e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "        'Imagine getting flattened by Kurt Zouma',\n",
       "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
       "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
       "        'destroy the free fandom honestly',\n",
       "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
       "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
       "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
       "       dtype=object),\n",
       " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first 10 training sentences and their labels\n",
    "train_sentences[:10], train_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157b6a2c",
   "metadata": {},
   "source": [
    "### Converting text into numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5903aaea",
   "metadata": {},
   "source": [
    "In NLP, there are two main concepts for turning text into numbers:\n",
    "\n",
    "Tokenization - A straight mapping from word or character or sub-word to a numerical value.\n",
    " \n",
    "There are three main levels of tokenization:\n",
    "\n",
    "Using word-level tokenization with the sentence \"I love TensorFlow\" might result in \"I\" being 0, \"love\" being 1 and \"TensorFlow\" being 2. In this case, every word in a sequence considered a single token.\n",
    "\n",
    "Character-level tokenization, such as converting the letters A-Z to values 1-26. In this case, every character in a sequence considered a single token.\n",
    "\n",
    "Sub-word tokenization is in between word-level and character-level tokenization. It involves breaking invidual words into smaller parts and then converting those smaller parts into numbers. For example, \"my favourite food is pineapple pizza\" might become \"my, fav, avour, rite, fo, oo, od, is, pin, ine, app, le, piz, za\". After doing this, these sub-words would then be mapped to a numerical value. In this case, every word could be considered multiple tokens.\n",
    "\n",
    "Embeddings - An embedding is a representation of natural language which can be learned. Representation comes in the form of a feature vector. For example, the word \"dance\" could be represented by the 5-dimensional vector [-0.8547, 0.4559, -0.3332, 0.9877, 0.1112]. It's important to note here, the size of the feature vector is tuneable. \n",
    "\n",
    "There are two ways to use embeddings:\n",
    "\n",
    "Create your own embedding - Once your text has been turned into numbers (required for an embedding), you can put them through an embedding layer (such as tf.keras.layers.Embedding) and an embedding representation will be learned during model training.\n",
    "\n",
    "Reuse a pre-learned embedding - Many pre-trained embeddings exist online. These pre-trained embeddings have often been learned on large corpuses of text (such as all of Wikipedia) and thus have a good underlying representation of natural language. You can use a pre-trained embedding to initialize your model and fine-tune it to your own specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d0d121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import TextVectorization\n",
    "\n",
    "# Use the default TextVectorization variables\n",
    "text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (all of the different words in your text)\n",
    "                                    standardize=\"lower_and_strip_punctuation\",\n",
    "                                    split=\"whitespace\", # How to split tokens\n",
    "                                    ngrams=None, # create groups of n-words?\n",
    "                                    output_mode=\"int\", # how to map tokens to numbers\n",
    "                                    output_sequence_length=None) # how long should the output sequence of tokens be?\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08500c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find average number of tokens (words) in training Tweets\n",
    "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75a4e56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup text vectorization with custom variables\n",
    "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
    "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bd695ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the text vectorizer to the training text\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba7289c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=int64)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create sample sentence and tokenize it\n",
    "sample_sentence = \"There's a flood in my street!\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968bf520",
   "metadata": {},
   "source": [
    "Wonderful, it seems we've got a way to turn our text into numbers (in this case, word-level tokenization). Notice the 0's at the end of the returned tensor, this is because we set output_sequence_length=15, meaning no matter the size of the sequence we pass to text_vectorizer, it always returns a sequence with a length of 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7b38b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab: 10000\n",
      "Top 5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
      "Bottom 5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique words in the vocabulary\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "top_5_words = words_in_vocab[:5] # most common tokens (notice the [UNK] token for \"unknown\" words)\n",
    "bottom_5_words = words_in_vocab[-5:] # least common tokens\n",
    "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
    "print(f\"Top 5 most common words: {top_5_words}\") \n",
    "print(f\"Bottom 5 least common words: {bottom_5_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bfe4e2",
   "metadata": {},
   "source": [
    "### Creating an Embedding using an Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5742abd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.core.embedding.Embedding at 0x1cbc233f850>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "from keras import layers\n",
    "\n",
    "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
    "                             output_dim=128, # set size of embedding vector\n",
    "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
    "                             input_length=max_length, # how long is each input\n",
    "                             name=\"embedding_1\") \n",
    "\n",
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdf6425",
   "metadata": {},
   "source": [
    "### Model 0: Getting a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "497e74ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('steps',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">steps&nbsp;</td>\n",
       "            <td class=\"value\">[(&#x27;tfidf&#x27;, ...), (&#x27;clf&#x27;, ...)]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('transform_input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">transform_input&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('memory',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">memory&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"tfidf__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">input&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;content&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('encoding',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">encoding&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;utf-8&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('decode_error',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">decode_error&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;strict&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('strip_accents',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">strip_accents&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('lowercase',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">lowercase&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('preprocessor',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">preprocessor&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tokenizer',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tokenizer&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('analyzer',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">analyzer&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;word&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('stop_words',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">stop_words&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('token_pattern',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">token_pattern&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;(?u)\\\\b\\\\w\\\\w+\\\\b&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ngram_range',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ngram_range&nbsp;</td>\n",
       "            <td class=\"value\">(1, ...)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_df',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_df&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_df',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_df&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('vocabulary',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">vocabulary&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('binary',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">binary&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dtype',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dtype&nbsp;</td>\n",
       "            <td class=\"value\">&lt;class &#x27;numpy.float64&#x27;&gt;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('norm',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">norm&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('use_idf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">use_idf&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('smooth_idf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">smooth_idf&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sublinear_tf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">sublinear_tf&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"clf__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">alpha&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('force_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">force_alpha&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_prior',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_prior&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_prior',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_prior&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create tokenization and modelling pipeline\n",
    "model_0 = Pipeline([\n",
    "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
    "                    (\"clf\", MultinomialNB()) # model the text\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "model_0.fit(train_sentences, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38604f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our baseline model achieves an accuracy of: 79.27%\n"
     ]
    }
   ],
   "source": [
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "579d55e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_preds[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93385316",
   "metadata": {},
   "source": [
    "### Creating an evaluation function for our model experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7a53798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate: accuracy, precision, recall, f1-score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "  \"\"\"\n",
    "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
    "\n",
    "  Args:\n",
    "  -----\n",
    "  y_true = true labels in the form of a 1D array\n",
    "  y_pred = predicted labels in the form of a 1D array\n",
    "\n",
    "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
    "  \"\"\"\n",
    "  # Calculate model accuracy\n",
    "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
    "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "  model_results = {\"accuracy\": model_accuracy,\n",
    "                  \"precision\": model_precision,\n",
    "                  \"recall\": model_recall,\n",
    "                  \"f1\": model_f1}\n",
    "  return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8a1bf15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get baseline results\n",
    "baseline_results = calculate_results(y_true=val_labels,\n",
    "                                     y_pred=baseline_preds)\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6196684",
   "metadata": {},
   "source": [
    "### Model 1: A simple dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee5780e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model with the Functional API\n",
    "from keras import layers\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\") # inputs are 1-dimensional strings\n",
    "x = text_vectorizer(inputs) # turn the input text into numbers\n",
    "x = embedding(x) # create an embedding of the numerized numbers\n",
    "x = layers.GlobalAveragePooling1D()(x) # lower the dimensionality of the embedding (try running the model without this layer and see what happens)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # create the output layer, want binary outputs so use sigmoid activation\n",
    "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") # construct the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a03bc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model_1.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7611a06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_2 (Text  (None, 15)                0         \n",
      " Vectorization)                                                  \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d (  (None, 128)               0         \n",
      " GlobalAveragePooling1D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1280129 (4.88 MB)\n",
      "Trainable params: 1280129 (4.88 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get a summary of the model\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef721126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From c:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "215/215 [==============================] - 2s 5ms/step - loss: 0.6086 - accuracy: 0.6919 - val_loss: 0.5356 - val_accuracy: 0.7559\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.4408 - accuracy: 0.8203 - val_loss: 0.4689 - val_accuracy: 0.7835\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.3460 - accuracy: 0.8612 - val_loss: 0.4588 - val_accuracy: 0.7913\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.2844 - accuracy: 0.8926 - val_loss: 0.4641 - val_accuracy: 0.7913\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.2375 - accuracy: 0.9130 - val_loss: 0.4768 - val_accuracy: 0.7887\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_1_history = model_1.fit(train_sentences, # input sentences can be a list of strings due to text preprocessing layer built-in model\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels)\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3c1a429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 672us/step - loss: 0.4768 - accuracy: 0.7887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4767613708972931, 0.7887139320373535]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the results\n",
    "model_1.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c35025d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 128)\n"
     ]
    }
   ],
   "source": [
    "embed_weights = model_1.get_layer(\"embedding_1\").get_weights()[0]\n",
    "print(embed_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "072512be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 727us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.41659036],\n",
       "       [0.74509037],\n",
       "       [0.9976933 ],\n",
       "       [0.10718403],\n",
       "       [0.10474802],\n",
       "       [0.9364471 ],\n",
       "       [0.91437817],\n",
       "       [0.99310607],\n",
       "       [0.969656  ],\n",
       "       [0.26342508]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions (these come back in the form of probabilities)\n",
    "model_1_pred_probs = model_1.predict(val_sentences)\n",
    "model_1_pred_probs[:10] # only print out the first 10 prediction probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8182cd93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn prediction probabilities into single-dimension tensor of floats\n",
    "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs)) # squeeze removes single dimensions\n",
    "model_1_preds[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc1915ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.87139107611549,\n",
       " 'precision': 0.7926581572076621,\n",
       " 'recall': 0.7887139107611548,\n",
       " 'f1': 0.7860944810879305}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_1 metrics\n",
    "model_1_results = calculate_results(y_true=val_labels, \n",
    "                                    y_pred=model_1_preds)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bfe2cc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 78.87, Difference: -0.39\n",
      "Baseline precision: 0.81, New precision: 0.79, Difference: -0.02\n",
      "Baseline recall: 0.79, New recall: 0.79, Difference: -0.00\n",
      "Baseline f1: 0.79, New f1: 0.79, Difference: -0.00\n"
     ]
    }
   ],
   "source": [
    "# Create a helper function to compare our baseline results to new model results\n",
    "def compare_baseline_to_new_results(baseline_results, new_model_results):\n",
    "  for key, value in baseline_results.items():\n",
    "    print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")\n",
    "\n",
    "compare_baseline_to_new_results(baseline_results=baseline_results, \n",
    "                                new_model_results=model_1_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0d277b",
   "metadata": {},
   "source": [
    "### Recurrent Neural Networks (RNN's)\n",
    "For our next series of modelling experiments we're going to be using a special kind of neural network called a Recurrent Neural Network (RNN).\n",
    "\n",
    "The premise of an RNN is simple: use information from the past to help you with the future (this is where the term recurrent comes from). In other words, take an input (X) and compute an output (y) based on all previous inputs.\n",
    "\n",
    "This concept is especially helpful when dealing with sequences such as passages of natural language text (such as our Tweets).\n",
    "\n",
    "For example, when you read this sentence, you take into context the previous words when deciphering the meaning of the current word dog.\n",
    "\n",
    "See what happened there?\n",
    "\n",
    "I put the word \"dog\" at the end which is a valid word but it doesn't make sense in the context of the rest of the sentence.\n",
    "\n",
    "When an RNN looks at a sequence of text (already in numerical form), the patterns it learns are continually updated based on the order of the sequence.\n",
    "\n",
    "For a simple example, take two sentences:\n",
    "\n",
    "Massive earthquake last week, no?\n",
    "No massive earthquake last week.\n",
    "Both contain exactly the same words but have different meaning. The order of the words determines the meaning (one could argue punctuation marks also dictate the meaning but for simplicity sake, let's stay focused on the words).\n",
    "\n",
    "Recurrent neural networks can be used for a number of sequence-based problems:\n",
    "\n",
    "One to one: one input, one output, such as image classification.\n",
    "One to many: one input, many outputs, such as image captioning (image input, a sequence of text as caption output).\n",
    "Many to one: many inputs, one outputs, such as text classification (classifying a Tweet as real diaster or not real diaster).\n",
    "Many to many: many inputs, many outputs, such as machine translation (translating English to Spanish) or speech to text (audio wave as input, text as output).\n",
    "When you come across RNN's in the wild, you'll most likely come across variants of the following:\n",
    "\n",
    "Long short-term memory cells (LSTMs).\n",
    "Gated recurrent units (GRUs).\n",
    "Bidirectional RNN's (passes forward and backward along a sequence, left to right and right to left)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddd799a",
   "metadata": {},
   "source": [
    "### Model 2: LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b90bc56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 128)\n",
      "(None, 64)\n"
     ]
    }
   ],
   "source": [
    "# Set random seed and create embedding layer (new embedding layer for each model)\n",
    "tf.random.set_seed(42)\n",
    "from keras import layers\n",
    "model_2_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                                     output_dim=128,\n",
    "                                     embeddings_initializer=\"uniform\",\n",
    "                                     input_length=max_length,\n",
    "                                     name=\"embedding_2\")\n",
    "\n",
    "\n",
    "# Create LSTM model\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_2_embedding(x)\n",
    "print(x.shape)\n",
    "# x = layers.LSTM(64, return_sequences=True)(x) # return vector for each word in the Tweet (you can stack RNN cells as long as return_sequences=True)\n",
    "x = layers.LSTM(64)(x) # return vector for whole sequence\n",
    "print(x.shape)\n",
    "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer on top of output of LSTM cell\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c5fedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Note: The reason we use a new embedding layer for each model is since the embedding layer is a\n",
    "#  learned representation of words (as numbers), \n",
    "# if we were to use the same embedding layer (embedding_1) for each model,\n",
    "#  we'd be mixing what one model learned with the next. \n",
    "# And because we want to compare our models later on, \n",
    "# starting them with their own embedding layer each time is a better idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b924b6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model_2.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c5e78066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 3s 8ms/step - loss: 0.5120 - accuracy: 0.7435 - val_loss: 0.4564 - val_accuracy: 0.7861\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.3196 - accuracy: 0.8723 - val_loss: 0.5145 - val_accuracy: 0.7822\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.2200 - accuracy: 0.9172 - val_loss: 0.6056 - val_accuracy: 0.7638\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.1535 - accuracy: 0.9454 - val_loss: 0.6197 - val_accuracy: 0.7717\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.1105 - accuracy: 0.9581 - val_loss: 0.7924 - val_accuracy: 0.7598\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "model_2_history = model_2.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3547667d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((762, 1),\n",
       " array([[0.01195139],\n",
       "        [0.7632109 ],\n",
       "        [0.99766284],\n",
       "        [0.09929636],\n",
       "        [0.00470507],\n",
       "        [0.9985415 ],\n",
       "        [0.96794343],\n",
       "        [0.9992396 ],\n",
       "        [0.9983212 ],\n",
       "        [0.29961884]], dtype=float32))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the validation dataset\n",
    "model_2_pred_probs = model_2.predict(val_sentences)\n",
    "model_2_pred_probs.shape, model_2_pred_probs[:10] # view the first 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f9b2bad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Round out predictions and reduce to 1-dimensional array\n",
    "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
    "model_2_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d905ce10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 75.98425196850394,\n",
       " 'precision': 0.760844531051619,\n",
       " 'recall': 0.7598425196850394,\n",
       " 'f1': 0.7578634561555267}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate LSTM model results\n",
    "model_2_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_2_preds)\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "89ead29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 75.98, Difference: -3.28\n",
      "Baseline precision: 0.81, New precision: 0.76, Difference: -0.05\n",
      "Baseline recall: 0.79, New recall: 0.76, Difference: -0.03\n",
      "Baseline f1: 0.79, New f1: 0.76, Difference: -0.03\n"
     ]
    }
   ],
   "source": [
    "# Compare model 2 to baseline\n",
    "compare_baseline_to_new_results(baseline_results, model_2_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bd0d55",
   "metadata": {},
   "source": [
    "### Model 3: GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d83c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed and create embedding layer (new embedding layer for each model)\n",
    "tf.random.set_seed(42)\n",
    "from keras import layers\n",
    "model_3_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                                     output_dim=128,\n",
    "                                     embeddings_initializer=\"uniform\",\n",
    "                                     input_length=max_length,\n",
    "                                     name=\"embedding_3\")\n",
    "\n",
    "# Build an RNN using the GRU cell\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_3_embedding(x)\n",
    "# x = layers.GRU(64, return_sequences=True) # stacking recurrent cells requires return_sequences=True\n",
    "x = layers.GRU(64)(x) \n",
    "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer after GRU cell\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2a33ed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile GRU model\n",
    "model_3.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b4b7415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 3s 7ms/step - loss: 0.5267 - accuracy: 0.7251 - val_loss: 0.4541 - val_accuracy: 0.7808\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.3183 - accuracy: 0.8692 - val_loss: 0.4883 - val_accuracy: 0.7835\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.2167 - accuracy: 0.9174 - val_loss: 0.5630 - val_accuracy: 0.7730\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.1544 - accuracy: 0.9460 - val_loss: 0.6120 - val_accuracy: 0.7795\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.1154 - accuracy: 0.9604 - val_loss: 0.6107 - val_accuracy: 0.7717\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "model_3_history = model_3.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a54939f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((762, 1),\n",
       " array([[0.38002962],\n",
       "        [0.89719045],\n",
       "        [0.9971204 ],\n",
       "        [0.14832169],\n",
       "        [0.01507458],\n",
       "        [0.99120253],\n",
       "        [0.6439899 ],\n",
       "        [0.9971398 ],\n",
       "        [0.99702024],\n",
       "        [0.44167814]], dtype=float32))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the validation data\n",
    "model_3_pred_probs = model_3.predict(val_sentences)\n",
    "model_3_pred_probs.shape, model_3_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ff159384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert prediction probabilities to prediction classes\n",
    "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
    "model_3_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9bb2ac7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.16535433070865,\n",
       " 'precision': 0.7714817611268913,\n",
       " 'recall': 0.7716535433070866,\n",
       " 'f1': 0.770792075286364}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcuate model_3 results\n",
    "model_3_results = calculate_results(y_true=val_labels, \n",
    "                                    y_pred=model_3_preds)\n",
    "model_3_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "581754f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 77.17, Difference: -2.10\n",
      "Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n",
      "Baseline recall: 0.79, New recall: 0.77, Difference: -0.02\n",
      "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
     ]
    }
   ],
   "source": [
    "# Compare to baseline\n",
    "compare_baseline_to_new_results(baseline_results, model_3_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe47a4b",
   "metadata": {},
   "source": [
    "### Model 4: Bidirectonal RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "80648625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed and create embedding layer (new embedding layer for each model)\n",
    "tf.random.set_seed(42)\n",
    "from keras import layers\n",
    "model_4_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                                     output_dim=128,\n",
    "                                     embeddings_initializer=\"uniform\",\n",
    "                                     input_length=max_length,\n",
    "                                     name=\"embedding_4\")\n",
    "\n",
    "# Build a Bidirectional RNN in TensorFlow\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_4_embedding(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x) # stacking RNN layers requires return_sequences=True\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x) # bidirectional goes both ways so has double the parameters of a regular LSTM layer\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidirectional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c2fdea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "model_4.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9a25f43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 5s 12ms/step - loss: 0.5053 - accuracy: 0.7532 - val_loss: 0.4537 - val_accuracy: 0.7861\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.3116 - accuracy: 0.8756 - val_loss: 0.5291 - val_accuracy: 0.7651\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.2077 - accuracy: 0.9202 - val_loss: 0.5635 - val_accuracy: 0.7585\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.1399 - accuracy: 0.9550 - val_loss: 0.6750 - val_accuracy: 0.7664\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.1021 - accuracy: 0.9680 - val_loss: 0.6805 - val_accuracy: 0.7625\n"
     ]
    }
   ],
   "source": [
    "# Fit the model (takes longer because of the bidirectional layers)\n",
    "model_4_history = model_4.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "23177d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00882705],\n",
       "       [0.8912377 ],\n",
       "       [0.9984109 ],\n",
       "       [0.09429356],\n",
       "       [0.01427896],\n",
       "       [0.99912506],\n",
       "       [0.939724  ],\n",
       "       [0.99924356],\n",
       "       [0.998779  ],\n",
       "       [0.13787746]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with bidirectional RNN on the validation data\n",
    "model_4_pred_probs = model_4.predict(val_sentences)\n",
    "model_4_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "72859dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert prediction probabilities to labels\n",
    "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
    "model_4_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "afd45a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.24671916010499,\n",
       " 'precision': 0.762420601385426,\n",
       " 'recall': 0.7624671916010499,\n",
       " 'f1': 0.7613223680610012}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate bidirectional RNN model results\n",
    "model_4_results = calculate_results(val_labels, model_4_preds)\n",
    "model_4_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f305ff20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 76.25, Difference: -3.02\n",
      "Baseline precision: 0.81, New precision: 0.76, Difference: -0.05\n",
      "Baseline recall: 0.79, New recall: 0.76, Difference: -0.03\n",
      "Baseline f1: 0.79, New f1: 0.76, Difference: -0.02\n"
     ]
    }
   ],
   "source": [
    "# Check to see how the bidirectional model performs against the baseline\n",
    "compare_baseline_to_new_results(baseline_results, model_4_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e022708",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks for Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84090570",
   "metadata": {},
   "source": [
    "The difference again is in the layers component. Instead of using an LSTM or GRU cell, we're going to use a tensorflow.keras.layers.Conv1D() layer followed by a tensorflow.keras.layers.GlobablMaxPool1D() layer.\n",
    "\n",
    "1-dimensional convolving filters are used as ngram detectors, each filter specializing in a closely-related family of ngrams (an ngram is a collection of n-words, for example, an ngram of 5 might result in \"hello, my name is Daniel\").\n",
    "Max-pooling over time extracts the relevant ngrams for making a decision.\n",
    "The rest of the network classifies the text based on this information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdda4ea",
   "metadata": {},
   "source": [
    "### Model 5: Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cb14bfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed and create embedding layer (new embedding layer for each model)\n",
    "tf.random.set_seed(42)\n",
    "from keras import layers\n",
    "model_5_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                                     output_dim=128,\n",
    "                                     embeddings_initializer=\"uniform\",\n",
    "                                     input_length=max_length,\n",
    "                                     name=\"embedding_5\")\n",
    "\n",
    "# Create 1-dimensional convolutional layer to model sequences\n",
    "from keras import layers\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_5_embedding(x)\n",
    "x = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")\n",
    "\n",
    "# Compile Conv1D model\n",
    "model_5.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "03444007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.5683 - accuracy: 0.7129 - val_loss: 0.4710 - val_accuracy: 0.7782\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.3479 - accuracy: 0.8567 - val_loss: 0.4691 - val_accuracy: 0.7979\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.2228 - accuracy: 0.9190 - val_loss: 0.5269 - val_accuracy: 0.7769\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.1457 - accuracy: 0.9508 - val_loss: 0.6069 - val_accuracy: 0.7743\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.1028 - accuracy: 0.9673 - val_loss: 0.6615 - val_accuracy: 0.7703\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_5_history = model_5.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "42f8b561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 848us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.6384701 ],\n",
       "       [0.7494809 ],\n",
       "       [0.9999189 ],\n",
       "       [0.12476136],\n",
       "       [0.00636451],\n",
       "       [0.99582464],\n",
       "       [0.97828835],\n",
       "       [0.99836075],\n",
       "       [0.9989208 ],\n",
       "       [0.16220908]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with model_5\n",
    "model_5_pred_probs = model_5.predict(val_sentences)\n",
    "model_5_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c28088c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert model_5 prediction probabilities to labels\n",
    "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
    "model_5_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8eee6eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.03412073490814,\n",
       " 'precision': 0.7732589791209112,\n",
       " 'recall': 0.7703412073490814,\n",
       " 'f1': 0.7676409049388612}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_5 evaluation metrics \n",
    "model_5_results = calculate_results(y_true=val_labels, \n",
    "                                    y_pred=model_5_preds)\n",
    "model_5_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5acf3ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 77.03, Difference: -2.23\n",
      "Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n",
      "Baseline recall: 0.79, New recall: 0.77, Difference: -0.02\n",
      "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
     ]
    }
   ],
   "source": [
    "# Compare model_5 results to baseline \n",
    "compare_baseline_to_new_results(baseline_results, model_5_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b901be",
   "metadata": {},
   "source": [
    "### Using Pretrained Embeddings (transfer learning for NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e62a47e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[-0.01157025  0.02485911  0.02878051 -0.012715    0.03971541  0.08827761\n",
      "  0.02680988  0.05589838 -0.01068731 -0.00597293  0.00639321 -0.01819516\n",
      "  0.00030816  0.09105889  0.05874645 -0.03180629  0.01512474 -0.05162925\n",
      "  0.00991366 -0.06865345 -0.04209306  0.0267898   0.03011009  0.00321065\n",
      " -0.00337968 -0.04787356  0.0226672  -0.00985927 -0.04063615 -0.01292093\n",
      " -0.04666382  0.05630299 -0.03949255  0.00517682  0.02495827 -0.07014439\n",
      "  0.0287151   0.0494768  -0.00633978 -0.08960193  0.02807119 -0.00808364\n",
      " -0.01360601  0.05998649 -0.10361788 -0.05195372  0.00232958 -0.02332531\n",
      " -0.03758106  0.03327729], shape=(50,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Example of pretrained embedding with universal sentence encoder - https://tfhub.dev/google/universal-sentence-encoder/4\n",
    "import tensorflow_hub as hub\n",
    "embed = hub.load(\"https://www.kaggle.com/models/google/universal-sentence-encoder/TensorFlow2/universal-sentence-encoder/2\") # load Universal Sentence Encoder\n",
    "embed_samples = embed([sample_sentence,\n",
    "                      \"When you call the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
    "\n",
    "print(embed_samples[0][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "67992492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use this encoding layer in place of our text_vectorizer and embedding layer\n",
    "sentence_encoder_layer = hub.KerasLayer(\"https://www.kaggle.com/models/google/universal-sentence-encoder/TensorFlow2/universal-sentence-encoder/2\",\n",
    "                                        input_shape=[], # shape of inputs coming to our model \n",
    "                                        dtype=tf.string, # data type of inputs coming to the USE layer\n",
    "                                        trainable=False, # keep the pretrained weights (we'll create a feature extractor)\n",
    "                                        name=\"USE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4a011112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6_USE\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " USE (KerasLayer)            (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256830721 (979.73 MB)\n",
      "Trainable params: 32897 (128.50 KB)\n",
      "Non-trainable params: 256797824 (979.61 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model using the Sequential API\n",
    "model_6 = tf.keras.Sequential([\n",
    "  sentence_encoder_layer, # take in sentences and then encode them into an embedding\n",
    "  layers.Dense(64, activation=\"relu\"),\n",
    "  layers.Dense(1, activation=\"sigmoid\")\n",
    "], name=\"model_6_USE\")\n",
    "\n",
    "# Compile model\n",
    "model_6.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e6fb20df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 2s 4ms/step - loss: 0.5042 - accuracy: 0.7841 - val_loss: 0.4478 - val_accuracy: 0.7940\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 1s 3ms/step - loss: 0.4154 - accuracy: 0.8143 - val_loss: 0.4374 - val_accuracy: 0.8058\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.4011 - accuracy: 0.8209 - val_loss: 0.4333 - val_accuracy: 0.8110\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 1s 3ms/step - loss: 0.3941 - accuracy: 0.8254 - val_loss: 0.4289 - val_accuracy: 0.8110\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.3883 - accuracy: 0.8285 - val_loss: 0.4305 - val_accuracy: 0.8189\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier on top of pretrained embeddings\n",
    "model_6_history = model_6.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "187fad81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.1435321 ],\n",
       "       [0.7451239 ],\n",
       "       [0.9861453 ],\n",
       "       [0.20314488],\n",
       "       [0.7270231 ],\n",
       "       [0.6843151 ],\n",
       "       [0.9774516 ],\n",
       "       [0.96970814],\n",
       "       [0.92598426],\n",
       "       [0.08730598]], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with USE TF Hub model\n",
    "model_6_pred_probs = model_6.predict(val_sentences)\n",
    "model_6_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "067d233a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert prediction probabilities to labels\n",
    "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
    "model_6_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3a5a5369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 81.88976377952756,\n",
       " 'precision': 0.8214432106294689,\n",
       " 'recall': 0.8188976377952756,\n",
       " 'f1': 0.8173559181868181}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model 6 performance metrics\n",
    "model_6_results = calculate_results(val_labels, model_6_preds)\n",
    "model_6_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "17c86273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 79.27, New accuracy: 81.89, Difference: 2.62\n",
      "Baseline precision: 0.81, New precision: 0.82, Difference: 0.01\n",
      "Baseline recall: 0.79, New recall: 0.82, Difference: 0.03\n",
      "Baseline f1: 0.79, New f1: 0.82, Difference: 0.03\n"
     ]
    }
   ],
   "source": [
    "# Compare TF Hub model to baseline\n",
    "compare_baseline_to_new_results(baseline_results, model_6_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bb9b2db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>79.265092</td>\n",
       "      <td>0.811139</td>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.786219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple_dense</th>\n",
       "      <td>78.871391</td>\n",
       "      <td>0.792658</td>\n",
       "      <td>0.788714</td>\n",
       "      <td>0.786094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lstm</th>\n",
       "      <td>75.984252</td>\n",
       "      <td>0.760845</td>\n",
       "      <td>0.759843</td>\n",
       "      <td>0.757863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gru</th>\n",
       "      <td>77.165354</td>\n",
       "      <td>0.771482</td>\n",
       "      <td>0.771654</td>\n",
       "      <td>0.770792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bidirectional</th>\n",
       "      <td>76.246719</td>\n",
       "      <td>0.762421</td>\n",
       "      <td>0.762467</td>\n",
       "      <td>0.761322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv1d</th>\n",
       "      <td>77.034121</td>\n",
       "      <td>0.773259</td>\n",
       "      <td>0.770341</td>\n",
       "      <td>0.767641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_hub_sentence_encoder</th>\n",
       "      <td>81.889764</td>\n",
       "      <td>0.821443</td>\n",
       "      <td>0.818898</td>\n",
       "      <td>0.817356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          accuracy  precision    recall        f1\n",
       "baseline                 79.265092   0.811139  0.792651  0.786219\n",
       "simple_dense             78.871391   0.792658  0.788714  0.786094\n",
       "lstm                     75.984252   0.760845  0.759843  0.757863\n",
       "gru                      77.165354   0.771482  0.771654  0.770792\n",
       "bidirectional            76.246719   0.762421  0.762467  0.761322\n",
       "conv1d                   77.034121   0.773259  0.770341  0.767641\n",
       "tf_hub_sentence_encoder  81.889764   0.821443  0.818898  0.817356"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine model results into a DataFrame\n",
    "all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n",
    "                                  \"simple_dense\": model_1_results,\n",
    "                                  \"lstm\": model_2_results,\n",
    "                                  \"gru\": model_3_results,\n",
    "                                  \"bidirectional\": model_4_results,\n",
    "                                  \"conv1d\": model_5_results,\n",
    "                                  \"tf_hub_sentence_encoder\": model_6_results})\n",
    "all_model_results = all_model_results.transpose()\n",
    "all_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f7dd671a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the accuracy to same scale as other metrics\n",
    "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "69256deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot and compare all of the model results\n",
    "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "645f3079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sort model results by f1-score\n",
    "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bde4c71",
   "metadata": {},
   "source": [
    "### Combining our models (model ensembling/stacking)\n",
    "\n",
    "Many production systems use an ensemble (multiple different models combined) of models to make a prediction.\n",
    "\n",
    "The idea behind model stacking is that if several uncorrelated models agree on a prediction, then the prediction must be more robust than a prediction made by a singular model.\n",
    "\n",
    "The keyword in the sentence above is uncorrelated, which is another way of saying, different types of models. For example, in our case, we might combine our baseline, our bidirectional model and our TensorFlow Hub USE model.\n",
    "\n",
    "Although these models are all trained on the same data, they all have a different way of finding patterns.\n",
    "\n",
    "If we were to use three similarly trained models, such as three LSTM models, the predictions they output will likely be very similar.\n",
    "\n",
    "Think of it as trying to decide where to eat with your friends. If you all have similar tastes, you'll probably all pick the same restaurant. But if you've all got different tastes and still end up picking the same restaurant, the restaurant must be good.\n",
    "\n",
    "Since we're working with a classification problem, there are a few of ways we can combine our models:\n",
    "\n",
    "Averaging - Take the output prediction probabilities of each model for each sample, combine them and then average them.\n",
    "\n",
    "Majority vote (mode) - Make class predictions with each of your models on all samples, the predicted class is the one in majority. For example, if three different models predict [1, 0, 1] respectively, the majority class is 1, therefore, that would be the predicted label.\n",
    "\n",
    "Model stacking - Take the outputs of each of your chosen models and use them as inputs to another model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "756cab31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get mean pred probs for 3 models\n",
    "import numpy as np\n",
    "baseline_pred_probs = np.max(model_0.predict_proba(val_sentences), axis=1) # get the prediction probabilities from baseline model\n",
    "combined_pred_probs = baseline_pred_probs + tf.squeeze(model_2_pred_probs, axis=1) + tf.squeeze(model_6_pred_probs)\n",
    "combined_preds = tf.round(combined_pred_probs/3) # average and round the prediction probabilities to get prediction classes\n",
    "combined_preds[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2a131cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.21522309711287,\n",
       " 'precision': 0.7820002933865271,\n",
       " 'recall': 0.7821522309711286,\n",
       " 'f1': 0.7814160583740962}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate results from averaging the prediction probabilities\n",
    "ensemble_results = calculate_results(val_labels, combined_preds)\n",
    "ensemble_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "35781611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add our combined model's results to the results DataFrame\n",
    "all_model_results.loc[\"ensemble_results\"] = ensemble_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3d1b59e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_24956\\3504904892.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_model_results.loc[\"ensemble_results\"][\"accuracy\"] = all_model_results.loc[\"ensemble_results\"][\"accuracy\"]/100\n"
     ]
    }
   ],
   "source": [
    "# Convert the accuracy to the same scale as the rest of the results\n",
    "all_model_results.loc[\"ensemble_results\"][\"accuracy\"] = all_model_results.loc[\"ensemble_results\"][\"accuracy\"]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "98a8b073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.811139</td>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.786219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple_dense</th>\n",
       "      <td>0.788714</td>\n",
       "      <td>0.792658</td>\n",
       "      <td>0.788714</td>\n",
       "      <td>0.786094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lstm</th>\n",
       "      <td>0.759843</td>\n",
       "      <td>0.760845</td>\n",
       "      <td>0.759843</td>\n",
       "      <td>0.757863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gru</th>\n",
       "      <td>0.771654</td>\n",
       "      <td>0.771482</td>\n",
       "      <td>0.771654</td>\n",
       "      <td>0.770792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bidirectional</th>\n",
       "      <td>0.762467</td>\n",
       "      <td>0.762421</td>\n",
       "      <td>0.762467</td>\n",
       "      <td>0.761322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv1d</th>\n",
       "      <td>0.770341</td>\n",
       "      <td>0.773259</td>\n",
       "      <td>0.770341</td>\n",
       "      <td>0.767641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_hub_sentence_encoder</th>\n",
       "      <td>0.818898</td>\n",
       "      <td>0.821443</td>\n",
       "      <td>0.818898</td>\n",
       "      <td>0.817356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble_results</th>\n",
       "      <td>78.215223</td>\n",
       "      <td>0.782000</td>\n",
       "      <td>0.782152</td>\n",
       "      <td>0.781416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          accuracy  precision    recall        f1\n",
       "baseline                  0.792651   0.811139  0.792651  0.786219\n",
       "simple_dense              0.788714   0.792658  0.788714  0.786094\n",
       "lstm                      0.759843   0.760845  0.759843  0.757863\n",
       "gru                       0.771654   0.771482  0.771654  0.770792\n",
       "bidirectional             0.762467   0.762421  0.762467  0.761322\n",
       "conv1d                    0.770341   0.773259  0.770341  0.767641\n",
       "tf_hub_sentence_encoder   0.818898   0.821443  0.818898  0.817356\n",
       "ensemble_results         78.215223   0.782000  0.782152  0.781416"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5c9ca5",
   "metadata": {},
   "source": [
    "### Finding the most wrong examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dbddf69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.745124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@camilacabello97 Internally and externally scr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Radiation emergency #preparedness starts with ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.727023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  pred  pred_prob\n",
       "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   0.0   0.143532\n",
       "1  FedEx no longer to transport bioterror germs i...       0   1.0   0.745124\n",
       "2  Gunmen kill four in El Salvador bus attack: Su...       1   1.0   0.986145\n",
       "3  @camilacabello97 Internally and externally scr...       1   0.0   0.203145\n",
       "4  Radiation emergency #preparedness starts with ...       1   1.0   0.727023"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe with validation sentences and best performing model predictions\n",
    "val_df = pd.DataFrame({\"text\": val_sentences,\n",
    "                       \"target\": val_labels,\n",
    "                       \"pred\": model_6_preds,\n",
    "                       \"pred_prob\": tf.squeeze(model_6_pred_probs)})\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4b85852e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.904433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>FedEx will no longer transport bioterror patho...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.865167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>@SonofLiberty357 all illuminated by the bright...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.855188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>@noah_anyname That's where the concentration c...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.846591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>@madonnamking RSPCA site multiple 7 story high...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Ashes 2015: AustraliaÛªs collapse at Trent Br...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.819569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.783977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.783839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>@RebeccaforReal accepts Wisconsin Emergency Re...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.774428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>åÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Ten...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.772719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  target  pred  \\\n",
       "31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   \n",
       "759  FedEx will no longer transport bioterror patho...       0   1.0   \n",
       "393  @SonofLiberty357 all illuminated by the bright...       0   1.0   \n",
       "628  @noah_anyname That's where the concentration c...       0   1.0   \n",
       "49   @madonnamking RSPCA site multiple 7 story high...       0   1.0   \n",
       "209  Ashes 2015: AustraliaÛªs collapse at Trent Br...       0   1.0   \n",
       "109  [55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...       0   1.0   \n",
       "251  @AshGhebranious civil rights continued in the ...       0   1.0   \n",
       "567  @RebeccaforReal accepts Wisconsin Emergency Re...       0   1.0   \n",
       "698  åÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Ten...       0   1.0   \n",
       "\n",
       "     pred_prob  \n",
       "31    0.904433  \n",
       "759   0.865167  \n",
       "393   0.855188  \n",
       "628   0.846591  \n",
       "49    0.833530  \n",
       "209   0.819569  \n",
       "109   0.783977  \n",
       "251   0.783839  \n",
       "567   0.774428  \n",
       "698   0.772719  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the wrong predictions and sort by prediction probabilities\n",
    "most_wrong = val_df[val_df[\"target\"] != val_df[\"pred\"]].sort_values(\"pred_prob\", ascending=False)\n",
    "most_wrong[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096817ba",
   "metadata": {},
   "source": [
    "Do you notice anything interesting about the most wrong samples?\n",
    "\n",
    "Are the ground truth labels correct? What do you think would happen if we went back and corrected the labels which aren't?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a49d3c0",
   "metadata": {},
   "source": [
    "### Making predictions on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f1f5d4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "Pred: 0, Prob: 0.15779024362564087\n",
      "Text:\n",
      "@spencer_ellmore @CentreTransfer just wait Norwich might hijack the deal??????\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Pred: 0, Prob: 0.11712486296892166\n",
      "Text:\n",
      "Lustig gets flattened...he should have stayed down longer..\n",
      "\n",
      "Commons coming on . my guess is GMS coming off...\n",
      "\n",
      "water break! 0-0  76mins\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Pred: 0, Prob: 0.4780725836753845\n",
      "Text:\n",
      "Ignition Knock (Detonation) Sensor-Senso BECK/ARNLEY 158-1028 http://t.co/YszIBvj3cs http://t.co/C9t0cGtjFw\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Pred: 1, Prob: 0.9547845125198364\n",
      "Text:\n",
      "17 dead as suicide bomber attacks Saudi Arabian mosque http://t.co/d5cUDwuhww | https://t.co/twnsWk0hFJ\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Pred: 0, Prob: 0.34338441491127014\n",
      "Text:\n",
      "Nuclear-Deal: Indo-Japan pact lies at the heart of two US reactor-based projects: If Japan were to go ahead an... http://t.co/mvwdm9ZbcV\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Pred: 0, Prob: 0.15357935428619385\n",
      "Text:\n",
      "The whole of New Zealand is shouting 'Bloody Marvellous'! John Campbell to join Radio NZ http://t.co/F88fCLiVzH #radionz\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Pred: 1, Prob: 0.9469708800315857\n",
      "Text:\n",
      "Flash floods landslides possible as Hanna draws in more monsoon rains - Pagasa http://t.co/TzWmsEQPHW | via News5 #iBalita\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Pred: 1, Prob: 0.7279006242752075\n",
      "Text:\n",
      "Latest fallout from biolab safety lapses: FedEx no longer will transport anthrax &amp; select agent research specimens http://t.co/4iOOyIbxyo\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Pred: 0, Prob: 0.02477075345814228\n",
      "Text:\n",
      "@BattyAfterDawn @DrawLiomDraw he's a good cute.  The kind of cute I want to obliterate.\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Pred: 1, Prob: 0.8395959734916687\n",
      "Text:\n",
      "Florida Firefighters Rescue Scared Meowing Kitten from Vent Shaft http://t.co/RVKffcxbvC #fire #firefighter\n",
      "\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Making predictions on the test dataset\n",
    "import random \n",
    "test_sentences = test_df[\"text\"].to_list()\n",
    "test_samples = random.sample(test_sentences, 10)\n",
    "for test_sample in test_samples:\n",
    "  pred_prob = tf.squeeze(model_6.predict([test_sample])) # has to be list\n",
    "  pred = tf.round(pred_prob)\n",
    "  print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n",
    "  print(f\"Text:\\n{test_sample}\\n\")\n",
    "  print(\"----\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
